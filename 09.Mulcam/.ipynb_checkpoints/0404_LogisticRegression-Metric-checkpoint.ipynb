{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20723e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 329\n",
      "sklearn의 결과 : 합격여부 : [1], 확률 : [[0.43740782 0.56259218]]\n",
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_8032\\2996139442.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_8032\\2996139442.py:92: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_8032\\2996139442.py:108: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_8032\\2996139442.py:108: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_8032\\2996139442.py:111: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_8032\\2996139442.py:111: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_8032\\2996139442.py:112: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_8032\\2996139442.py:112: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss의 값 : 0.6468270421028137\n",
      "loss의 값 : 0.6386728882789612\n",
      "loss의 값 : 0.6323645710945129\n",
      "loss의 값 : 0.6268954277038574\n",
      "loss의 값 : 0.6220735311508179\n",
      "loss의 값 : 0.6178140044212341\n",
      "loss의 값 : 0.6140462160110474\n",
      "loss의 값 : 0.6107109189033508\n",
      "loss의 값 : 0.6077460646629333\n",
      "loss의 값 : 0.6051058173179626\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model  # sklearn으로 logistic 구현\n",
    "from sklearn.preprocessing import MinMaxScaler  # 정규화 진행\n",
    "from scipy import stats   # 이상치 처리\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "# 경고메시지 출력하지 않아요!\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('../../data/admission.csv')\n",
    "\n",
    "#############################\n",
    "# preprocessing\n",
    "#############################\n",
    "\n",
    "# 결측치부터 살펴보아야 해요!\n",
    "# print(df.isnull().sum())   # 결치값은 없네요!!\n",
    "# df.info()\n",
    "\n",
    "# 이상치가 있는지를 확인하고 처리해 보아요!\n",
    "# 종속변수의 이상치를 outlier\n",
    "# 독립변수의 이상치를 지대값\n",
    "# 이상치가 존재하는지를 눈으로 확인하는 가장 쉬운 방법은 boxplot\n",
    "# figure = plt.figure()\n",
    "# ax1 = figure.add_subplot(1,4,1)\n",
    "# ax2 = figure.add_subplot(1,4,2)\n",
    "# ax3 = figure.add_subplot(1,4,3)\n",
    "# ax4 = figure.add_subplot(1,4,4)\n",
    "# ax1.set_title('ADMIT')\n",
    "# ax2.set_title('GRE')\n",
    "# ax3.set_title('GPA')\n",
    "# ax4.set_title('RANK')\n",
    "\n",
    "# ax1.boxplot(df['admit'])\n",
    "# ax2.boxplot(df['gre'])\n",
    "# ax3.boxplot(df['gpa'])\n",
    "# ax4.boxplot(df['rank'])\n",
    "\n",
    "# figure.tight_layout()\n",
    "# plt.show()\n",
    "# boxplot을 이용해서 눈으로 확인보니 이상치가 존재하네요!!\n",
    "# z-score를 이용해서 이상치를 제거하고 진행해 보아요!\n",
    "zscore_threshold = 2.0\n",
    "\n",
    "for col in df.columns:\n",
    "    outlier = df[col][np.abs(stats.zscore(df[col])) > zscore_threshold]\n",
    "    df = df.loc[~df[col].isin(outlier)]\n",
    "    \n",
    "# 이상치를 제거했으니 정규화를 진행\n",
    "# display(df.head())\n",
    "x_data = df.drop('admit', axis=1, inplace=False)\n",
    "t_data = df['admit'].values.reshape(-1,1)  \n",
    "# t_data는 0과 1로만 구성되어 있어요. 따라서 정규화를 할 필요가 없어요!\n",
    "\n",
    "# 정규화를 하기 위해 scaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "\n",
    "norm_x_data = scaler.transform(x_data)\n",
    "# print(norm_x_data)\n",
    "\n",
    "# training data set\n",
    "# norm_x_data\n",
    "# t_data\n",
    "\n",
    "### sklearn 구현\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "model.fit(x_data, t_data)\n",
    "\n",
    "my_score = np.array([[600, 3.8, 1]])\n",
    "predict_val = model.predict(my_score)    # 0 or 1로 결과 도출\n",
    "predict_proba = model.predict_proba(my_score) # 확률값으로 결과를 도출\n",
    "\n",
    "print('sklearn의 결과 : 합격여부 : {}, 확률 : {}'.format(predict_val, \n",
    "                                                         predict_proba))\n",
    "\n",
    "##############################\n",
    "# tensorflow 구현\n",
    "\n",
    "# training data set\n",
    "# norm_x_data\n",
    "# t_data\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([3,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis, model, predict model, logistic regression model\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function, cross entropy, log loss라고 하기도 해요!\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복학습\n",
    "\n",
    "for step in range(300000):\n",
    "    _, loss_val = sess.run([train, loss], \n",
    "                           feed_dict={X: norm_x_data,\n",
    "                                      T: t_data})\n",
    "    \n",
    "    if step % 30000 == 0:\n",
    "        print('loss의 값 : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_score = np.array([[600, 3.8, 1]])\n",
    "norm_my_score = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3ea7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF15] *",
   "language": "python",
   "name": "conda-env-machine_TF15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
