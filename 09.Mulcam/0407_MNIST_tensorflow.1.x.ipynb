{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49727e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971774f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/digit-recognizer/train.csv')\n",
    "df_test = pd.read_csv('../../data/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c521004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 확인\n",
    "figure = plt.figure()\n",
    "ax_arr = []  # python list\n",
    "\n",
    "img_data = df.drop('label', axis=1, inplace=False).values\n",
    "\n",
    "for n in range(10):\n",
    "    ax_arr.append(figure.add_subplot(2,5,n+1))\n",
    "    ax_arr[n].imshow(img_data[n].reshape(28,28), \n",
    "                     cmap='Greys',            # 흑백이미지 표현\n",
    "                     interpolation='nearest') # 보간법\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43675fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 385\n"
     ]
    }
   ],
   "source": [
    "train_x_data, test_x_data, train_t_data, test_t_data = train_test_split(df.drop('label', axis=1, inplace=False), df['label'], test_size=0.3, random_state=1, stratify=df['label'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40d5e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_7364\\2739525339.py:2: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_7364\\2739525339.py:2: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_7364\\2739525339.py:8: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_7364\\2739525339.py:8: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_7364\\2739525339.py:24: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_7364\\2739525339.py:24: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_7364\\2739525339.py:27: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Changhyun\\AppData\\Local\\Temp\\ipykernel_7364\\2739525339.py:27: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss val : 1.1130518913269043\n",
      "loss val : 0.24291673302650452\n",
      "loss val : 0.20340701937675476\n",
      "loss val : 0.1966889202594757\n",
      "loss val : 0.1963789165019989\n",
      "loss val : 0.19648805260658264\n",
      "loss val : 0.1960849165916443\n",
      "loss val : 0.1952027529478073\n",
      "loss val : 0.194045290350914\n",
      "loss val : 0.1928004026412964\n"
     ]
    }
   ],
   "source": [
    "## Tensorflow Implementation ##\n",
    "sess = tf.Session()\n",
    "\n",
    "onehot_train_t_data = sess.run(tf.one_hot(train_t_data, depth=10))\n",
    "onehot_test_t_data = sess.run(tf.one_hot(test_t_data, depth=10))\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([784,10]))\n",
    "b = tf.Variable(tf.random.normal([10]))\n",
    "\n",
    "# Hypothesis, Model\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "# Loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                 labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "\n",
    "# session, 초기화\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 반복학습\n",
    "num_of_epoch = 1000\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    \n",
    "    total_batch = int(norm_train_x_data.shape[0] / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_x = norm_train_x_data[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y = onehot_train_t_data[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        _, loss_val = sess.run([train, loss], feed_dict={X:batch_x,\n",
    "                                                         T:batch_y})\n",
    "    if step % 100 == 0:\n",
    "        print('loss val : {}'.format(loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff84be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9088095426559448\n"
     ]
    }
   ],
   "source": [
    "predict = tf.argmax(H, 1)\n",
    "correct = tf.equal(predict, tf.argmax(T, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "accuracy_val = sess.run(accuracy, feed_dict={X: norm_test_x_data,\n",
    "                                             T: onehot_test_t_data})\n",
    "\n",
    "print('Accuracy : {}'.format(accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79bf8eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3725b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.078523]\n"
     ]
    }
   ],
   "source": [
    "W = tf.random.normal([1], dtype=tf.float32)\n",
    "print(W.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8bd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe8019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/digit-recognizer/train.csv')\n",
    "df_test = pd.read_csv('../../data/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74975aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_data, test_x_data, train_t_data, test_t_data = train_test_split(df.drop('label', axis=1, inplace=False), df['label'], test_size=0.3, random_state=1, stratify=df['label'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bffa8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(norm_train_x_data.shape[1],)))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8f6e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "236/236 [==============================] - 2s 3ms/step - loss: 2.1891 - accuracy: 0.1960 - val_loss: 2.0723 - val_accuracy: 0.2823\n",
      "Epoch 2/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.9784 - accuracy: 0.3730 - val_loss: 1.8805 - val_accuracy: 0.4731\n",
      "Epoch 3/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.8031 - accuracy: 0.5454 - val_loss: 1.7194 - val_accuracy: 0.6095\n",
      "Epoch 4/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.6554 - accuracy: 0.6424 - val_loss: 1.5838 - val_accuracy: 0.6726\n",
      "Epoch 5/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.5309 - accuracy: 0.6933 - val_loss: 1.4695 - val_accuracy: 0.7088\n",
      "Epoch 6/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.4257 - accuracy: 0.7211 - val_loss: 1.3727 - val_accuracy: 0.7333\n",
      "Epoch 7/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3364 - accuracy: 0.7434 - val_loss: 1.2903 - val_accuracy: 0.7539\n",
      "Epoch 8/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2602 - accuracy: 0.7583 - val_loss: 1.2199 - val_accuracy: 0.7709\n",
      "Epoch 9/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1948 - accuracy: 0.7709 - val_loss: 1.1591 - val_accuracy: 0.7816\n",
      "Epoch 10/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1381 - accuracy: 0.7804 - val_loss: 1.1064 - val_accuracy: 0.7918\n",
      "Epoch 11/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0886 - accuracy: 0.7894 - val_loss: 1.0601 - val_accuracy: 0.8014\n",
      "Epoch 12/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0451 - accuracy: 0.7971 - val_loss: 1.0192 - val_accuracy: 0.8088\n",
      "Epoch 13/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0066 - accuracy: 0.8038 - val_loss: 0.9831 - val_accuracy: 0.8122\n",
      "Epoch 14/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9723 - accuracy: 0.8087 - val_loss: 0.9508 - val_accuracy: 0.8160\n",
      "Epoch 15/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9415 - accuracy: 0.8133 - val_loss: 0.9218 - val_accuracy: 0.8197\n",
      "Epoch 16/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9138 - accuracy: 0.8172 - val_loss: 0.8954 - val_accuracy: 0.8236\n",
      "Epoch 17/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8886 - accuracy: 0.8216 - val_loss: 0.8716 - val_accuracy: 0.8267\n",
      "Epoch 18/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8657 - accuracy: 0.8247 - val_loss: 0.8499 - val_accuracy: 0.8301\n",
      "Epoch 19/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8448 - accuracy: 0.8275 - val_loss: 0.8300 - val_accuracy: 0.8321\n",
      "Epoch 20/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8255 - accuracy: 0.8298 - val_loss: 0.8116 - val_accuracy: 0.8337\n",
      "Epoch 21/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8078 - accuracy: 0.8335 - val_loss: 0.7948 - val_accuracy: 0.8352\n",
      "Epoch 22/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7914 - accuracy: 0.8356 - val_loss: 0.7791 - val_accuracy: 0.8376\n",
      "Epoch 23/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7762 - accuracy: 0.8375 - val_loss: 0.7646 - val_accuracy: 0.8386\n",
      "Epoch 24/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7620 - accuracy: 0.8392 - val_loss: 0.7511 - val_accuracy: 0.8398\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7488 - accuracy: 0.8409 - val_loss: 0.7385 - val_accuracy: 0.8427\n",
      "Epoch 26/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7364 - accuracy: 0.8432 - val_loss: 0.7267 - val_accuracy: 0.8437\n",
      "Epoch 27/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7248 - accuracy: 0.8450 - val_loss: 0.7155 - val_accuracy: 0.8449\n",
      "Epoch 28/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7139 - accuracy: 0.8464 - val_loss: 0.7051 - val_accuracy: 0.8457\n",
      "Epoch 29/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7037 - accuracy: 0.8478 - val_loss: 0.6953 - val_accuracy: 0.8471\n",
      "Epoch 30/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.8492 - val_loss: 0.6860 - val_accuracy: 0.8488\n",
      "Epoch 31/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6848 - accuracy: 0.8498 - val_loss: 0.6772 - val_accuracy: 0.8503\n",
      "Epoch 32/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6761 - accuracy: 0.8514 - val_loss: 0.6689 - val_accuracy: 0.8517\n",
      "Epoch 33/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6678 - accuracy: 0.8523 - val_loss: 0.6610 - val_accuracy: 0.8527\n",
      "Epoch 34/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6600 - accuracy: 0.8532 - val_loss: 0.6535 - val_accuracy: 0.8537\n",
      "Epoch 35/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6526 - accuracy: 0.8542 - val_loss: 0.6464 - val_accuracy: 0.8546\n",
      "Epoch 36/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6454 - accuracy: 0.8550 - val_loss: 0.6396 - val_accuracy: 0.8556\n",
      "Epoch 37/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6387 - accuracy: 0.8553 - val_loss: 0.6331 - val_accuracy: 0.8565\n",
      "Epoch 38/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6322 - accuracy: 0.8562 - val_loss: 0.6269 - val_accuracy: 0.8575\n",
      "Epoch 39/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6260 - accuracy: 0.8572 - val_loss: 0.6210 - val_accuracy: 0.8582\n",
      "Epoch 40/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6200 - accuracy: 0.8579 - val_loss: 0.6153 - val_accuracy: 0.8587\n",
      "Epoch 41/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6143 - accuracy: 0.8589 - val_loss: 0.6098 - val_accuracy: 0.8587\n",
      "Epoch 42/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6089 - accuracy: 0.8597 - val_loss: 0.6046 - val_accuracy: 0.8590\n",
      "Epoch 43/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6036 - accuracy: 0.8607 - val_loss: 0.5996 - val_accuracy: 0.8602\n",
      "Epoch 44/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5986 - accuracy: 0.8611 - val_loss: 0.5948 - val_accuracy: 0.8609\n",
      "Epoch 45/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5937 - accuracy: 0.8617 - val_loss: 0.5901 - val_accuracy: 0.8611\n",
      "Epoch 46/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5890 - accuracy: 0.8621 - val_loss: 0.5856 - val_accuracy: 0.8611\n",
      "Epoch 47/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5845 - accuracy: 0.8632 - val_loss: 0.5813 - val_accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5801 - accuracy: 0.8636 - val_loss: 0.5771 - val_accuracy: 0.8621\n",
      "Epoch 49/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5759 - accuracy: 0.8643 - val_loss: 0.5731 - val_accuracy: 0.8631\n",
      "Epoch 50/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5718 - accuracy: 0.8645 - val_loss: 0.5692 - val_accuracy: 0.8634\n",
      "Epoch 51/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5679 - accuracy: 0.8650 - val_loss: 0.5655 - val_accuracy: 0.8639\n",
      "Epoch 52/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5641 - accuracy: 0.8656 - val_loss: 0.5619 - val_accuracy: 0.8645\n",
      "Epoch 53/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5604 - accuracy: 0.8659 - val_loss: 0.5583 - val_accuracy: 0.8648\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.8662 - val_loss: 0.5549 - val_accuracy: 0.8665\n",
      "Epoch 55/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5534 - accuracy: 0.8667 - val_loss: 0.5516 - val_accuracy: 0.8673\n",
      "Epoch 56/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5500 - accuracy: 0.8673 - val_loss: 0.5484 - val_accuracy: 0.8680\n",
      "Epoch 57/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5467 - accuracy: 0.8679 - val_loss: 0.5453 - val_accuracy: 0.8680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5436 - accuracy: 0.8683 - val_loss: 0.5423 - val_accuracy: 0.8687\n",
      "Epoch 59/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5405 - accuracy: 0.8687 - val_loss: 0.5393 - val_accuracy: 0.8689\n",
      "Epoch 60/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5375 - accuracy: 0.8693 - val_loss: 0.5365 - val_accuracy: 0.8694\n",
      "Epoch 61/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5346 - accuracy: 0.8696 - val_loss: 0.5337 - val_accuracy: 0.8697\n",
      "Epoch 62/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.8700 - val_loss: 0.5310 - val_accuracy: 0.8706\n",
      "Epoch 63/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5290 - accuracy: 0.8703 - val_loss: 0.5284 - val_accuracy: 0.8711\n",
      "Epoch 64/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5263 - accuracy: 0.8707 - val_loss: 0.5258 - val_accuracy: 0.8709\n",
      "Epoch 65/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5237 - accuracy: 0.8711 - val_loss: 0.5233 - val_accuracy: 0.8713\n",
      "Epoch 66/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5211 - accuracy: 0.8716 - val_loss: 0.5209 - val_accuracy: 0.8714\n",
      "Epoch 67/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5186 - accuracy: 0.8718 - val_loss: 0.5185 - val_accuracy: 0.8716\n",
      "Epoch 68/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5162 - accuracy: 0.8723 - val_loss: 0.5162 - val_accuracy: 0.8718\n",
      "Epoch 69/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5139 - accuracy: 0.8726 - val_loss: 0.5140 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5115 - accuracy: 0.8730 - val_loss: 0.5118 - val_accuracy: 0.8726\n",
      "Epoch 71/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5093 - accuracy: 0.8736 - val_loss: 0.5096 - val_accuracy: 0.8726\n",
      "Epoch 72/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5071 - accuracy: 0.8741 - val_loss: 0.5075 - val_accuracy: 0.8735\n",
      "Epoch 73/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5049 - accuracy: 0.8746 - val_loss: 0.5055 - val_accuracy: 0.8735\n",
      "Epoch 74/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5028 - accuracy: 0.8750 - val_loss: 0.5035 - val_accuracy: 0.8735\n",
      "Epoch 75/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5007 - accuracy: 0.8751 - val_loss: 0.5015 - val_accuracy: 0.8736\n",
      "Epoch 76/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4987 - accuracy: 0.8754 - val_loss: 0.4996 - val_accuracy: 0.8738\n",
      "Epoch 77/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4968 - accuracy: 0.8759 - val_loss: 0.4977 - val_accuracy: 0.8740\n",
      "Epoch 78/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4948 - accuracy: 0.8763 - val_loss: 0.4959 - val_accuracy: 0.8740\n",
      "Epoch 79/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4929 - accuracy: 0.8761 - val_loss: 0.4941 - val_accuracy: 0.8745\n",
      "Epoch 80/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4911 - accuracy: 0.8767 - val_loss: 0.4923 - val_accuracy: 0.8745\n",
      "Epoch 81/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.8768 - val_loss: 0.4906 - val_accuracy: 0.8747\n",
      "Epoch 82/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4875 - accuracy: 0.8770 - val_loss: 0.4889 - val_accuracy: 0.8747\n",
      "Epoch 83/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4857 - accuracy: 0.8774 - val_loss: 0.4873 - val_accuracy: 0.8750\n",
      "Epoch 84/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4840 - accuracy: 0.8780 - val_loss: 0.4857 - val_accuracy: 0.8753\n",
      "Epoch 85/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4824 - accuracy: 0.8781 - val_loss: 0.4841 - val_accuracy: 0.8755\n",
      "Epoch 86/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.8784 - val_loss: 0.4825 - val_accuracy: 0.8755\n",
      "Epoch 87/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4791 - accuracy: 0.8786 - val_loss: 0.4810 - val_accuracy: 0.8757\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4775 - accuracy: 0.8789 - val_loss: 0.4795 - val_accuracy: 0.8760\n",
      "Epoch 89/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4760 - accuracy: 0.8793 - val_loss: 0.4780 - val_accuracy: 0.8762\n",
      "Epoch 90/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4744 - accuracy: 0.8796 - val_loss: 0.4766 - val_accuracy: 0.8764\n",
      "Epoch 91/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4729 - accuracy: 0.8798 - val_loss: 0.4752 - val_accuracy: 0.8769\n",
      "Epoch 92/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4715 - accuracy: 0.8803 - val_loss: 0.4738 - val_accuracy: 0.8760\n",
      "Epoch 93/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4700 - accuracy: 0.8803 - val_loss: 0.4724 - val_accuracy: 0.8770\n",
      "Epoch 94/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.8806 - val_loss: 0.4711 - val_accuracy: 0.8776\n",
      "Epoch 95/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4672 - accuracy: 0.8809 - val_loss: 0.4698 - val_accuracy: 0.8776\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.8812 - val_loss: 0.4685 - val_accuracy: 0.8774\n",
      "Epoch 97/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.8816 - val_loss: 0.4672 - val_accuracy: 0.8774\n",
      "Epoch 98/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4631 - accuracy: 0.8819 - val_loss: 0.4659 - val_accuracy: 0.8776\n",
      "Epoch 99/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4618 - accuracy: 0.8819 - val_loss: 0.4647 - val_accuracy: 0.8779\n",
      "Epoch 100/100\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4606 - accuracy: 0.8825 - val_loss: 0.4635 - val_accuracy: 0.8781\n"
     ]
    }
   ],
   "source": [
    "# model compile\n",
    "# 사용할 loss 함수를 지정, 사용한 optimizer(알고리즘)를 지정\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# loss\n",
    "# linear regression : linear\n",
    "# binary classification : binary_crossentropy\n",
    "# multinomial classification : categorical_crossentropy(onehot encoding처리를 해야 해요!)\n",
    "# multinomial classification : sparse_categorical_crossentropy(onehot처리가 필요 없어요!)\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 학습결과를 변수에 저장\n",
    "history = model.fit(norm_train_x_data,\n",
    "                    train_t_data,\n",
    "                    epochs=100,\n",
    "                    batch_size=100,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f609274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 1s 2ms/step - loss: 0.4751 - accuracy: 0.8766\n",
      "[0.47507286071777344, 0.8765873312950134]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(norm_test_x_data, test_t_data))\n",
    "#        loss               accuracy\n",
    "# [0.4799305200576782, 0.876031756401062]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "678124c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_11 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "236/236 [==============================] - ETA: 0s - loss: 2.2652 - accuracy: 0.1507\n",
      "Epoch 00001: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 2.2652 - accuracy: 0.1507 - val_loss: 2.1471 - val_accuracy: 0.2236\n",
      "Epoch 2/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 2.0410 - accuracy: 0.3056\n",
      "Epoch 00002: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 2.0391 - accuracy: 0.3075 - val_loss: 1.9451 - val_accuracy: 0.4116\n",
      "Epoch 3/100\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 1.8569 - accuracy: 0.4973\n",
      "Epoch 00003: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.8551 - accuracy: 0.4979 - val_loss: 1.7763 - val_accuracy: 0.5646\n",
      "Epoch 4/100\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.7009 - accuracy: 0.6019\n",
      "Epoch 00004: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.7006 - accuracy: 0.6020 - val_loss: 1.6343 - val_accuracy: 0.6366\n",
      "Epoch 5/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.5714 - accuracy: 0.6606\n",
      "Epoch 00005: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.5704 - accuracy: 0.6608 - val_loss: 1.5144 - val_accuracy: 0.6782\n",
      "Epoch 6/100\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 1.4640 - accuracy: 0.6932\n",
      "Epoch 00006: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.4605 - accuracy: 0.6946 - val_loss: 1.4131 - val_accuracy: 0.7061\n",
      "Epoch 7/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 1.3680 - accuracy: 0.7178\n",
      "Epoch 00007: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.3674 - accuracy: 0.7178 - val_loss: 1.3271 - val_accuracy: 0.7274\n",
      "Epoch 8/100\n",
      "234/236 [============================>.] - ETA: 0s - loss: 1.2880 - accuracy: 0.7362\n",
      "Epoch 00008: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.2880 - accuracy: 0.7362 - val_loss: 1.2533 - val_accuracy: 0.7437\n",
      "Epoch 9/100\n",
      "218/236 [==========================>...] - ETA: 0s - loss: 1.2209 - accuracy: 0.7512\n",
      "Epoch 00009: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2198 - accuracy: 0.7511 - val_loss: 1.1899 - val_accuracy: 0.7595\n",
      "Epoch 10/100\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 1.1603 - accuracy: 0.7652\n",
      "Epoch 00010: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 1.1609 - accuracy: 0.7642 - val_loss: 1.1349 - val_accuracy: 0.7711\n",
      "Epoch 11/100\n",
      "230/236 [============================>.] - ETA: 0s - loss: 1.1102 - accuracy: 0.7753\n",
      "Epoch 00011: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1094 - accuracy: 0.7756 - val_loss: 1.0867 - val_accuracy: 0.7820\n",
      "Epoch 12/100\n",
      "235/236 [============================>.] - ETA: 0s - loss: 1.0643 - accuracy: 0.7843\n",
      "Epoch 00012: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0643 - accuracy: 0.7844 - val_loss: 1.0443 - val_accuracy: 0.7905\n",
      "Epoch 13/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 1.0255 - accuracy: 0.7931\n",
      "Epoch 00013: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0244 - accuracy: 0.7934 - val_loss: 1.0068 - val_accuracy: 0.7974\n",
      "Epoch 14/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.9911 - accuracy: 0.7986\n",
      "Epoch 00014: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9888 - accuracy: 0.7991 - val_loss: 0.9732 - val_accuracy: 0.8046\n",
      "Epoch 15/100\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.9594 - accuracy: 0.8047\n",
      "Epoch 00015: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9570 - accuracy: 0.8049 - val_loss: 0.9431 - val_accuracy: 0.8095\n",
      "Epoch 16/100\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.9294 - accuracy: 0.8093\n",
      "Epoch 00016: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.9284 - accuracy: 0.8094 - val_loss: 0.9159 - val_accuracy: 0.8158\n",
      "Epoch 17/100\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.9038 - accuracy: 0.8130\n",
      "Epoch 00017: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9024 - accuracy: 0.8135 - val_loss: 0.8911 - val_accuracy: 0.8204\n",
      "Epoch 18/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.8787 - accuracy: 0.8171\n",
      "Epoch 00018: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8787 - accuracy: 0.8173 - val_loss: 0.8686 - val_accuracy: 0.8243\n",
      "Epoch 19/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.8574 - accuracy: 0.8206\n",
      "Epoch 00019: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8572 - accuracy: 0.8204 - val_loss: 0.8480 - val_accuracy: 0.8265\n",
      "Epoch 20/100\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.8370 - accuracy: 0.8243 ETA: 0s - loss: 0.8380 - accuracy: \n",
      "Epoch 00020: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8373 - accuracy: 0.8236 - val_loss: 0.8291 - val_accuracy: 0.8291\n",
      "Epoch 21/100\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.8186 - accuracy: 0.8267\n",
      "Epoch 00021: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8191 - accuracy: 0.8267 - val_loss: 0.8116 - val_accuracy: 0.8308\n",
      "Epoch 22/100\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.8030 - accuracy: 0.8285\n",
      "Epoch 00022: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8022 - accuracy: 0.8289 - val_loss: 0.7955 - val_accuracy: 0.8330\n",
      "Epoch 23/100\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.7864 - accuracy: 0.8311\n",
      "Epoch 00023: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7866 - accuracy: 0.8309 - val_loss: 0.7805 - val_accuracy: 0.8349\n",
      "Epoch 24/100\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.7715 - accuracy: 0.8332\n",
      "Epoch 00024: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7720 - accuracy: 0.8328 - val_loss: 0.7665 - val_accuracy: 0.8371\n",
      "Epoch 25/100\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.8353\n",
      "Epoch 00025: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7584 - accuracy: 0.8353 - val_loss: 0.7535 - val_accuracy: 0.8393\n",
      "Epoch 26/100\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.7458 - accuracy: 0.8371\n",
      "Epoch 00026: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7457 - accuracy: 0.8371 - val_loss: 0.7412 - val_accuracy: 0.8412\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/236 [==========================>...] - ETA: 0s - loss: 0.7350 - accuracy: 0.8386\n",
      "Epoch 00027: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7338 - accuracy: 0.8390 - val_loss: 0.7298 - val_accuracy: 0.8422\n",
      "Epoch 28/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.7236 - accuracy: 0.8401 ETA: 0s - loss: 0.7283 - accuracy: \n",
      "Epoch 00028: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.7226 - accuracy: 0.8403 - val_loss: 0.7190 - val_accuracy: 0.8429\n",
      "Epoch 29/100\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.7121 - accuracy: 0.8420\n",
      "Epoch 00029: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7121 - accuracy: 0.8420 - val_loss: 0.7089 - val_accuracy: 0.8432\n",
      "Epoch 30/100\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.7009 - accuracy: 0.8439\n",
      "Epoch 00030: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7021 - accuracy: 0.8431 - val_loss: 0.6993 - val_accuracy: 0.8440\n",
      "Epoch 31/100\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.6926 - accuracy: 0.8454\n",
      "Epoch 00031: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.8447 - val_loss: 0.6902 - val_accuracy: 0.8447\n",
      "Epoch 32/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.6840 - accuracy: 0.8461\n",
      "Epoch 00032: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.6838 - accuracy: 0.8464 - val_loss: 0.6817 - val_accuracy: 0.8457\n",
      "Epoch 33/100\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.6756 - accuracy: 0.8476\n",
      "Epoch 00033: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6754 - accuracy: 0.8475 - val_loss: 0.6735 - val_accuracy: 0.8480\n",
      "Epoch 34/100\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.6657 - accuracy: 0.8496\n",
      "Epoch 00034: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6674 - accuracy: 0.8490 - val_loss: 0.6658 - val_accuracy: 0.8507\n",
      "Epoch 35/100\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.6599 - accuracy: 0.8504\n",
      "Epoch 00035: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6597 - accuracy: 0.8503 - val_loss: 0.6584 - val_accuracy: 0.8515\n",
      "Epoch 36/100\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 0.6510 - accuracy: 0.8526\n",
      "Epoch 00036: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6524 - accuracy: 0.8512 - val_loss: 0.6514 - val_accuracy: 0.8529\n",
      "Epoch 37/100\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.6455 - accuracy: 0.8525\n",
      "Epoch 00037: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6455 - accuracy: 0.8524 - val_loss: 0.6447 - val_accuracy: 0.8532\n",
      "Epoch 38/100\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.6389 - accuracy: 0.8528\n",
      "Epoch 00038: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6388 - accuracy: 0.8528 - val_loss: 0.6382 - val_accuracy: 0.8549\n",
      "Epoch 39/100\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.6326 - accuracy: 0.8534\n",
      "Epoch 00039: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6325 - accuracy: 0.8537 - val_loss: 0.6321 - val_accuracy: 0.8554\n",
      "Epoch 40/100\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.6262 - accuracy: 0.8545\n",
      "Epoch 00040: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.8544 - val_loss: 0.6263 - val_accuracy: 0.8558\n",
      "Epoch 41/100\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.6204 - accuracy: 0.8552\n",
      "Epoch 00041: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6206 - accuracy: 0.8551 - val_loss: 0.6207 - val_accuracy: 0.8566\n",
      "Epoch 42/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.6151 - accuracy: 0.8557\n",
      "Epoch 00042: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6150 - accuracy: 0.8557 - val_loss: 0.6152 - val_accuracy: 0.8566\n",
      "Epoch 43/100\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 0.6114 - accuracy: 0.8560\n",
      "Epoch 00043: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6096 - accuracy: 0.8570 - val_loss: 0.6101 - val_accuracy: 0.8577\n",
      "Epoch 44/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.6027 - accuracy: 0.8584\n",
      "Epoch 00044: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6044 - accuracy: 0.8577 - val_loss: 0.6051 - val_accuracy: 0.8577\n",
      "Epoch 45/100\n",
      "213/236 [==========================>...] - ETA: 0s - loss: 0.5992 - accuracy: 0.8592\n",
      "Epoch 00045: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5995 - accuracy: 0.8590 - val_loss: 0.6003 - val_accuracy: 0.8588\n",
      "Epoch 46/100\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.5927 - accuracy: 0.8606\n",
      "Epoch 00046: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.8596 - val_loss: 0.5957 - val_accuracy: 0.8595\n",
      "Epoch 47/100\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.5894 - accuracy: 0.8608\n",
      "Epoch 00047: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5901 - accuracy: 0.8606 - val_loss: 0.5912 - val_accuracy: 0.8599\n",
      "Epoch 48/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.5855 - accuracy: 0.8613\n",
      "Epoch 00048: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5856 - accuracy: 0.8614 - val_loss: 0.5869 - val_accuracy: 0.8604\n",
      "Epoch 49/100\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.5808 - accuracy: 0.8627\n",
      "Epoch 00049: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5813 - accuracy: 0.8623 - val_loss: 0.5827 - val_accuracy: 0.8614\n",
      "Epoch 50/100\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.8627\n",
      "Epoch 00050: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5771 - accuracy: 0.8627 - val_loss: 0.5787 - val_accuracy: 0.8621\n",
      "Epoch 51/100\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.5724 - accuracy: 0.8631\n",
      "Epoch 00051: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5731 - accuracy: 0.8630 - val_loss: 0.5748 - val_accuracy: 0.8629\n",
      "Epoch 52/100\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.5690 - accuracy: 0.8645\n",
      "Epoch 00052: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5692 - accuracy: 0.8641 - val_loss: 0.5711 - val_accuracy: 0.8633\n",
      "Epoch 53/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.5656 - accuracy: 0.8645\n",
      "Epoch 00053: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5654 - accuracy: 0.8645 - val_loss: 0.5674 - val_accuracy: 0.8636\n",
      "Epoch 54/100\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.8652\n",
      "Epoch 00054: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5618 - accuracy: 0.8652 - val_loss: 0.5639 - val_accuracy: 0.8641\n",
      "Epoch 55/100\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.5583 - accuracy: 0.8661\n",
      "Epoch 00055: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5582 - accuracy: 0.8656 - val_loss: 0.5605 - val_accuracy: 0.8643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.5539 - accuracy: 0.8665\n",
      "Epoch 00056: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5548 - accuracy: 0.8663 - val_loss: 0.5572 - val_accuracy: 0.8650\n",
      "Epoch 57/100\n",
      "221/236 [===========================>..] - ETA: 0s - loss: 0.5508 - accuracy: 0.8671\n",
      "Epoch 00057: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5515 - accuracy: 0.8670 - val_loss: 0.5540 - val_accuracy: 0.8653\n",
      "Epoch 58/100\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.5486 - accuracy: 0.8674\n",
      "Epoch 00058: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5482 - accuracy: 0.8673 - val_loss: 0.5509 - val_accuracy: 0.8655\n",
      "Epoch 59/100\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.5454 - accuracy: 0.8680\n",
      "Epoch 00059: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5451 - accuracy: 0.8683 - val_loss: 0.5478 - val_accuracy: 0.8660\n",
      "Epoch 60/100\n",
      "231/236 [============================>.] - ETA: 0s - loss: 0.5427 - accuracy: 0.8682\n",
      "Epoch 00060: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.5420 - accuracy: 0.8685 - val_loss: 0.5449 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.5393 - accuracy: 0.8687\n",
      "Epoch 00061: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5390 - accuracy: 0.8690 - val_loss: 0.5420 - val_accuracy: 0.8670\n",
      "Epoch 62/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.5371 - accuracy: 0.8694\n",
      "Epoch 00062: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5361 - accuracy: 0.8694 - val_loss: 0.5392 - val_accuracy: 0.8672\n",
      "Epoch 63/100\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.5324 - accuracy: 0.8707\n",
      "Epoch 00063: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5333 - accuracy: 0.8700 - val_loss: 0.5365 - val_accuracy: 0.8675\n",
      "Epoch 64/100\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 0.5314 - accuracy: 0.8704\n",
      "Epoch 00064: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.5306 - accuracy: 0.8707 - val_loss: 0.5339 - val_accuracy: 0.8680\n",
      "Epoch 65/100\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.5257 - accuracy: 0.8714\n",
      "Epoch 00065: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5279 - accuracy: 0.8711 - val_loss: 0.5313 - val_accuracy: 0.8680\n",
      "Epoch 66/100\n",
      "235/236 [============================>.] - ETA: 0s - loss: 0.5251 - accuracy: 0.8714\n",
      "Epoch 00066: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5253 - accuracy: 0.8713 - val_loss: 0.5288 - val_accuracy: 0.8684\n",
      "Epoch 67/100\n",
      "232/236 [============================>.] - ETA: 0s - loss: 0.5229 - accuracy: 0.8714\n",
      "Epoch 00067: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5227 - accuracy: 0.8716 - val_loss: 0.5264 - val_accuracy: 0.8685\n",
      "Epoch 68/100\n",
      "223/236 [===========================>..] - ETA: 0s - loss: 0.5210 - accuracy: 0.8719\n",
      "Epoch 00068: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.8718 - val_loss: 0.5240 - val_accuracy: 0.8690\n",
      "Epoch 69/100\n",
      "213/236 [==========================>...] - ETA: 0s - loss: 0.5172 - accuracy: 0.8735\n",
      "Epoch 00069: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5178 - accuracy: 0.8724 - val_loss: 0.5216 - val_accuracy: 0.8687\n",
      "Epoch 70/100\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.5149 - accuracy: 0.8731\n",
      "Epoch 00070: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.8725 - val_loss: 0.5194 - val_accuracy: 0.8690\n",
      "Epoch 71/100\n",
      "222/236 [===========================>..] - ETA: 0s - loss: 0.5111 - accuracy: 0.8738\n",
      "Epoch 00071: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5132 - accuracy: 0.8732 - val_loss: 0.5171 - val_accuracy: 0.8690\n",
      "Epoch 72/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.5099 - accuracy: 0.8738\n",
      "Epoch 00072: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5109 - accuracy: 0.8736 - val_loss: 0.5150 - val_accuracy: 0.8701\n",
      "Epoch 73/100\n",
      "224/236 [===========================>..] - ETA: 0s - loss: 0.5069 - accuracy: 0.8744\n",
      "Epoch 00073: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5087 - accuracy: 0.8737 - val_loss: 0.5128 - val_accuracy: 0.8706\n",
      "Epoch 74/100\n",
      "226/236 [===========================>..] - ETA: 0s - loss: 0.5064 - accuracy: 0.8738\n",
      "Epoch 00074: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.8741 - val_loss: 0.5108 - val_accuracy: 0.8704\n",
      "Epoch 75/100\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.5057 - accuracy: 0.8740\n",
      "Epoch 00075: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.8744 - val_loss: 0.5087 - val_accuracy: 0.8704\n",
      "Epoch 76/100\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.5009 - accuracy: 0.8754\n",
      "Epoch 00076: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.8748 - val_loss: 0.5068 - val_accuracy: 0.8706\n",
      "Epoch 77/100\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.4999 - accuracy: 0.8754\n",
      "Epoch 00077: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.8750 - val_loss: 0.5048 - val_accuracy: 0.8707\n",
      "Epoch 78/100\n",
      "215/236 [==========================>...] - ETA: 0s - loss: 0.5001 - accuracy: 0.8742\n",
      "Epoch 00078: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4984 - accuracy: 0.8756 - val_loss: 0.5029 - val_accuracy: 0.8716\n",
      "Epoch 79/100\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.4958 - accuracy: 0.8762\n",
      "Epoch 00079: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.8759 - val_loss: 0.5011 - val_accuracy: 0.8718\n",
      "Epoch 80/100\n",
      "230/236 [============================>.] - ETA: 0s - loss: 0.4952 - accuracy: 0.8755\n",
      "Epoch 00080: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.8759 - val_loss: 0.4993 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.4922 - accuracy: 0.8764\n",
      "Epoch 00081: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4927 - accuracy: 0.8764 - val_loss: 0.4975 - val_accuracy: 0.8724\n",
      "Epoch 82/100\n",
      "233/236 [============================>.] - ETA: 0s - loss: 0.4906 - accuracy: 0.8767\n",
      "Epoch 00082: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4909 - accuracy: 0.8766 - val_loss: 0.4958 - val_accuracy: 0.8726\n",
      "Epoch 83/100\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.4893 - accuracy: 0.8762\n",
      "Epoch 00083: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.8767 - val_loss: 0.4940 - val_accuracy: 0.8726\n",
      "Epoch 84/100\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 0.4862 - accuracy: 0.8779\n",
      "Epoch 00084: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.8772 - val_loss: 0.4923 - val_accuracy: 0.8733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.4846 - accuracy: 0.8777\n",
      "Epoch 00085: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4856 - accuracy: 0.8776 - val_loss: 0.4907 - val_accuracy: 0.8735\n",
      "Epoch 86/100\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.4839 - accuracy: 0.8780\n",
      "Epoch 00086: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4839 - accuracy: 0.8779 - val_loss: 0.4891 - val_accuracy: 0.8738\n",
      "Epoch 87/100\n",
      "219/236 [==========================>...] - ETA: 0s - loss: 0.4829 - accuracy: 0.8783\n",
      "Epoch 00087: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4823 - accuracy: 0.8784 - val_loss: 0.4875 - val_accuracy: 0.8741\n",
      "Epoch 88/100\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.8786\n",
      "Epoch 00088: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.8786 - val_loss: 0.4859 - val_accuracy: 0.8741\n",
      "Epoch 89/100\n",
      "228/236 [===========================>..] - ETA: 0s - loss: 0.4800 - accuracy: 0.8782\n",
      "Epoch 00089: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4791 - accuracy: 0.8787 - val_loss: 0.4844 - val_accuracy: 0.8743\n",
      "Epoch 90/100\n",
      "225/236 [===========================>..] - ETA: 0s - loss: 0.4777 - accuracy: 0.8793\n",
      "Epoch 00090: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4775 - accuracy: 0.8791 - val_loss: 0.4829 - val_accuracy: 0.8745\n",
      "Epoch 91/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.4744 - accuracy: 0.8805\n",
      "Epoch 00091: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4760 - accuracy: 0.8793 - val_loss: 0.4815 - val_accuracy: 0.8747\n",
      "Epoch 92/100\n",
      "227/236 [===========================>..] - ETA: 0s - loss: 0.4739 - accuracy: 0.8796\n",
      "Epoch 00092: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4745 - accuracy: 0.8794 - val_loss: 0.4800 - val_accuracy: 0.8747\n",
      "Epoch 93/100\n",
      "216/236 [==========================>...] - ETA: 0s - loss: 0.4711 - accuracy: 0.8801\n",
      "Epoch 00093: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4730 - accuracy: 0.8796 - val_loss: 0.4786 - val_accuracy: 0.8750\n",
      "Epoch 94/100\n",
      "214/236 [==========================>...] - ETA: 0s - loss: 0.4708 - accuracy: 0.8804\n",
      "Epoch 00094: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4715 - accuracy: 0.8801 - val_loss: 0.4772 - val_accuracy: 0.8759\n",
      "Epoch 95/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.4708 - accuracy: 0.8791\n",
      "Epoch 00095: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.8799 - val_loss: 0.4759 - val_accuracy: 0.8760\n",
      "Epoch 96/100\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.4687 - accuracy: 0.8803\n",
      "Epoch 00096: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4687 - accuracy: 0.8803 - val_loss: 0.4745 - val_accuracy: 0.8762\n",
      "Epoch 97/100\n",
      "220/236 [==========================>...] - ETA: 0s - loss: 0.4695 - accuracy: 0.8794\n",
      "Epoch 00097: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4673 - accuracy: 0.8804 - val_loss: 0.4732 - val_accuracy: 0.8765\n",
      "Epoch 98/100\n",
      "229/236 [============================>.] - ETA: 0s - loss: 0.4657 - accuracy: 0.8809\n",
      "Epoch 00098: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8807 - val_loss: 0.4719 - val_accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "234/236 [============================>.] - ETA: 0s - loss: 0.4646 - accuracy: 0.8810\n",
      "Epoch 00099: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4646 - accuracy: 0.8810 - val_loss: 0.4707 - val_accuracy: 0.8769\n",
      "Epoch 100/100\n",
      "217/236 [==========================>...] - ETA: 0s - loss: 0.4623 - accuracy: 0.8814 ETA: 0s - loss: 0.4532 - \n",
      "Epoch 00100: saving model to ../../training_ckpt\\cp.ckpt\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4633 - accuracy: 0.8811 - val_loss: 0.4694 - val_accuracy: 0.8769\n",
      "394/394 [==============================] - 1s 2ms/step - loss: 0.4796 - accuracy: 0.8772\n",
      "[0.47957196831703186, 0.8772222399711609]\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "# 학습한 후 모델이 메모리에 저장. 프로그램 종료하면 학습한 모델이 사라짐\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = train_test_split(df.drop('label', axis=1, inplace=False), df['label'], test_size=0.3, random_state=1, stratify=df['label'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(norm_train_x_data.shape[1],)))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# loss\n",
    "# linear regression : linear\n",
    "# binary classification : binary_crossentropy\n",
    "# multinomial classification : categorical_crossentropy(onehot encoding처리를 해야 해요!)\n",
    "# multinomial classification : sparse_categorical_crossentropy(onehot처리가 필요 없어요!)\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 저장. model 구조 뺴고 checkpoint기능을 이용해서 weight, bias만 저장\n",
    "checkpoint_path = '../../training_ckpt/cp.ckpt'\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path) # 실제 경로로 만들어 준다\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                              save_weights_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "# 학습결과를 변수에 저장\n",
    "history = model.fit(norm_train_x_data,\n",
    "                    train_t_data,\n",
    "                    epochs=100,\n",
    "                    batch_size=100,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[cp_callback])\n",
    "\n",
    "print(model.evaluate(norm_test_x_data, test_t_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b83b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8eb96266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "394/394 [==============================] - 1s 2ms/step - loss: 2.3538 - accuracy: 0.1023\n",
      "[2.3537538051605225, 0.10230159014463425]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "df = pd.read_csv('../../data/digit-recognizer/train.csv')\n",
    "df_test = pd.read_csv('../../data/digit-recognizer/test.csv')\n",
    "\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = train_test_split(df.drop('label', axis=1, inplace=False), df['label'], test_size=0.3, random_state=1, stratify=df['label'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(norm_train_x_data.shape[1],)))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# loss\n",
    "# linear regression : linear\n",
    "# binary classification : binary_crossentropy\n",
    "# multinomial classification : categorical_crossentropy(onehot encoding처리를 해야 해요!)\n",
    "# multinomial classification : sparse_categorical_crossentropy(onehot처리가 필요 없어요!)\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.evaluate(norm_test_x_data, test_t_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "956c9a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 [==============================] - 1s 3ms/step - loss: 0.4796 - accuracy: 0.8772\n",
      "[0.47957196831703186, 0.8772222399711609]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '../../training_ckpt/cp.ckpt'\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "print(model.evaluate(norm_test_x_data, test_t_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49894c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a8e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a9623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27f0d629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1134732315874370091\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 4158062592\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 4729692591723486489\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dab91e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "CPU를 사용한 학습\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 717.4432 - accuracy: 0.1119\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 2.3013 - accuracy: 0.1124\n",
      "GPU를 사용한 학습\n",
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3012 - accuracy: 0.1124\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3013 - accuracy: 0.1124\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3013 - accuracy: 0.1124\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 넘파이 데이터를 텐서 데이터로 변환\n",
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "y_train = tf.one_hot(y_train, depth=len(np.unique(y_train)))\n",
    "y_test = tf.one_hot(y_test, depth=len(np.unique(y_train)))\n",
    "\n",
    "# 레이어 설계\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(), metrics=['accuracy'])\n",
    "\n",
    "# CPU 학습\n",
    "print(\"CPU를 사용한 학습\")\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    model.fit(x_train, y_train, batch_size=32, epochs=3)\n",
    "\n",
    "print(\"GPU를 사용한 학습\")\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    model.fit(x_train, y_train, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ad125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
