{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f28429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e3b2b4",
   "metadata": {},
   "source": [
    "### Keras의 Pretrained 모델 로딩 및 모델 구조확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc9ea1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 6s 0us/step\n",
      "553476096/553467096 [==============================] - 6s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31289101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "58900480/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e73eba",
   "metadata": {},
   "source": [
    "### Keras의 Model 역시 Functional임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3489cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <keras.engine.functional.Functional object at 0x000001D33F0FC700>\n",
      "model output: KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 512), dtype=tf.float32, name=None), name='block5_pool/MaxPool:0', description=\"created by layer 'block5_pool'\")\n"
     ]
    }
   ],
   "source": [
    "print('model:', model)\n",
    "print('model output:', model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89da49",
   "metadata": {},
   "source": [
    "### Pretrained 모델을 기반으로 CIFAR 10 분류 모델 재 생성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "492c86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b095b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                25650     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,740,848\n",
      "Trainable params: 14,740,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, Flatten, Activation, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "base_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE ,3), include_top=False, weights='imagenet')\n",
    "bm_output = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(bm_output)\n",
    "# x = Dropout(rate=0.5)(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "# x = Dropout(rate=0.2)(x)\n",
    "output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f8b7",
   "metadata": {},
   "source": [
    "### 데이터 전처리 및 ImageDataGenerator로 Augmentation 설정하고 학습용, 검증용 Generator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9e3d078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random as python_random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
    "def set_random_seed(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    python_random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
    "def get_preprocessed_data(images, labels, scaling=True):\n",
    "    \n",
    "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
    "    if scaling:\n",
    "        images = np.array(images/255.0, dtype=np.float32)\n",
    "    else:\n",
    "        images = np.array(images, dtype=np.float32)\n",
    "        \n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
    "def get_preprocessed_ohe(images, labels):\n",
    "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
    "    # OHE 적용 \n",
    "    oh_labels = to_categorical(labels)\n",
    "    return images, oh_labels\n",
    "\n",
    "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
    "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
    "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
    "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
    "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
    "    \n",
    "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
    "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
    "    \n",
    "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
    "\n",
    "\n",
    "# random seed는 2021로 고정.\n",
    "set_random_seed(2021)\n",
    "# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
    "\n",
    "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
    "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
    "\n",
    "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c16d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    # rotation_range=20,\n",
    "    #zoom_range=(0.7, 0.9),\n",
    "    horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    "    rescale=1/255.0\n",
    ")\n",
    "valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
    "flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfc12e",
   "metadata": {},
   "source": [
    "### Keras CNN 모델 생성 함수. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873d145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dafaac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "\n",
    "def create_model(verbose=False):\n",
    "    \n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    bm_output = base_model.output\n",
    "\n",
    "    x = GlobalAveragePooling2D()(bm_output)\n",
    "    #x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(50, activation='relu', name='fc1')(x)\n",
    "    #x = Dropout(rate=0.2)(x)\n",
    "    output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    if verbose:\n",
    "        model.summary()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6dce0a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 50)                25650     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,740,848\n",
      "Trainable params: 14,740,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model = create_model(verbose=True)\n",
    "vgg_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24cf85df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "665/665 [==============================] - 29s 38ms/step - loss: 1.8313 - accuracy: 0.2745 - val_loss: 1.5043 - val_accuracy: 0.4052 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 25s 37ms/step - loss: 1.3544 - accuracy: 0.4858 - val_loss: 1.2531 - val_accuracy: 0.5468 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 1.0752 - accuracy: 0.6185 - val_loss: 1.0242 - val_accuracy: 0.6481 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.8899 - accuracy: 0.6936 - val_loss: 0.8235 - val_accuracy: 0.7125 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.7824 - accuracy: 0.7324 - val_loss: 0.8665 - val_accuracy: 0.7067 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.6952 - accuracy: 0.7680 - val_loss: 0.7260 - val_accuracy: 0.7597 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.6550 - accuracy: 0.7834 - val_loss: 0.7001 - val_accuracy: 0.7684 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.5929 - accuracy: 0.8027 - val_loss: 0.7433 - val_accuracy: 0.7564 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.5478 - accuracy: 0.8194 - val_loss: 0.7282 - val_accuracy: 0.7668 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.5183 - accuracy: 0.8309 - val_loss: 0.6010 - val_accuracy: 0.8049 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.4695 - accuracy: 0.8467 - val_loss: 0.6297 - val_accuracy: 0.7996 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.4488 - accuracy: 0.8527 - val_loss: 0.5926 - val_accuracy: 0.8172 - lr: 0.0010\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.4223 - accuracy: 0.8608 - val_loss: 0.6299 - val_accuracy: 0.8005 - lr: 0.0010\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.3911 - accuracy: 0.8723 - val_loss: 0.6335 - val_accuracy: 0.8095 - lr: 0.0010\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.3795 - accuracy: 0.8785 - val_loss: 0.6220 - val_accuracy: 0.8192 - lr: 0.0010\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.3600 - accuracy: 0.8841 - val_loss: 0.5904 - val_accuracy: 0.8340 - lr: 0.0010\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.3362 - accuracy: 0.8928 - val_loss: 0.5964 - val_accuracy: 0.8255 - lr: 0.0010\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.3272 - accuracy: 0.8933 - val_loss: 0.7980 - val_accuracy: 0.7987 - lr: 0.0010\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.3148 - accuracy: 0.9006 - val_loss: 0.5933 - val_accuracy: 0.8252 - lr: 0.0010\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.3097 - accuracy: 0.9025 - val_loss: 0.6045 - val_accuracy: 0.8315 - lr: 0.0010\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.2810 - accuracy: 0.9106\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "665/665 [==============================] - 24s 37ms/step - loss: 0.2810 - accuracy: 0.9106 - val_loss: 0.6511 - val_accuracy: 0.8251 - lr: 0.0010\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.1563 - accuracy: 0.9506 - val_loss: 0.5993 - val_accuracy: 0.8459 - lr: 2.0000e-04\n",
      "Epoch 23/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.1135 - accuracy: 0.9649 - val_loss: 0.6116 - val_accuracy: 0.8472 - lr: 2.0000e-04\n",
      "Epoch 24/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.0861 - accuracy: 0.9740 - val_loss: 0.6771 - val_accuracy: 0.8439 - lr: 2.0000e-04\n",
      "Epoch 25/40\n",
      "665/665 [==============================] - 24s 36ms/step - loss: 0.0702 - accuracy: 0.9790 - val_loss: 0.7268 - val_accuracy: 0.8465 - lr: 2.0000e-04\n",
      "Epoch 26/40\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 0.9822\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "665/665 [==============================] - 25s 37ms/step - loss: 0.0616 - accuracy: 0.9822 - val_loss: 0.7644 - val_accuracy: 0.8460 - lr: 2.0000e-04\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\n",
    "tr_data_len = tr_images.shape[0]\n",
    "val_data_len = val_images.shape[0]\n",
    "history = vgg_model.fit(flow_tr_gen, epochs=40, \n",
    "                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
    "                    validation_data=flow_val_gen,\n",
    "                    validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
    "                    callbacks=[rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a442b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 12ms/step - loss: 0.8400 - accuracy: 0.8404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8400310277938843, 0.840399980545044]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "flow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
    "vgg_model.evaluate(flow_test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c861d03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_history(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.xticks(np.arange(0, 30, 2))\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='valid')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049edb9e",
   "metadata": {},
   "source": [
    "### 지금까지의 로직들을 함수화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5269e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf15a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import random as python_random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
    "def set_random_seed(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    python_random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
    "def get_preprocessed_data(images, labels, scaling=True):\n",
    "    \n",
    "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
    "    if scaling:\n",
    "        images = np.array(images/255.0, dtype=np.float32)\n",
    "    else:\n",
    "        images = np.array(images, dtype=np.float32)\n",
    "        \n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
    "def get_preprocessed_ohe(images, labels):\n",
    "    images, labels = get_preprocessed_data(images, labels, scaling=False)\n",
    "    # OHE 적용 \n",
    "    oh_labels = to_categorical(labels)\n",
    "    return images, oh_labels\n",
    "\n",
    "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
    "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
    "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
    "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
    "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
    "    \n",
    "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
    "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
    "    \n",
    "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
    "\n",
    "# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n",
    "# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \n",
    "def get_resized_images(images, resize=64):\n",
    "    image_cnt = images.shape[0]\n",
    "    resized_images = np.zeros((images.shape[0], resize, resize, 3))\n",
    "    for i in range(image_cnt):\n",
    "        resized_image = cv2.resize(images[i], (resize, resize))\n",
    "        resized_images[i] = resized_image\n",
    "    \n",
    "    return resized_images\n",
    "\n",
    "def create_model(model_name='vgg16', verbose=False):\n",
    "    \n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    if model_name == 'vgg16':\n",
    "        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'resnet50':\n",
    "        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    elif model_name == 'xception':\n",
    "        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
    "    \n",
    "    bm_output = base_model.output\n",
    "\n",
    "    x = GlobalAveragePooling2D()(bm_output)\n",
    "    if model_name != 'vgg16':\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(50, activation='relu', name='fc1')(x)\n",
    "    output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    model.summary()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dce7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n",
    "    set_random_seed(2021)\n",
    "    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
    "        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
    "    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n",
    "    \n",
    "    # 만약 image_size가 32보다 크면 이미지 크기 재조정. \n",
    "    if image_size > 32:\n",
    "        tr_images = get_resized_images(tr_images)\n",
    "        val_images = get_resized_images(val_images)\n",
    "        test_images = get_resized_images(test_images)\n",
    "    \n",
    "    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성. \n",
    "    train_generator = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        rescale=1/255.0\n",
    "    )\n",
    "    valid_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "    test_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행. \n",
    "    model = create_model(model_name=model_name, verbose=True)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
    "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
    "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "    \n",
    "    tr_data_len = tr_images.shape[0]\n",
    "    val_data_len = val_images.shape[0]\n",
    "    history = model.fit(flow_tr_gen, epochs=40, \n",
    "                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n",
    "                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n",
    "                        callbacks=[rlr_cb, ely_cb])\n",
    "    # 테스트 데이터 세트로 모델 성능 검증 \n",
    "    evaluation_result = model.evaluate(flow_test_gen)\n",
    "    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n",
    "    return history, evaluation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1fb75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21fc3d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 shape: (42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 15, 15, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " block1_conv1_bn (BatchNormaliz  (None, 15, 15, 32)  128         ['block1_conv1[0][0]']           \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block1_conv1_act (Activation)  (None, 15, 15, 32)   0           ['block1_conv1_bn[0][0]']        \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 13, 13, 64)   18432       ['block1_conv1_act[0][0]']       \n",
      "                                                                                                  \n",
      " block1_conv2_bn (BatchNormaliz  (None, 13, 13, 64)  256         ['block1_conv2[0][0]']           \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " block1_conv2_act (Activation)  (None, 13, 13, 64)   0           ['block1_conv2_bn[0][0]']        \n",
      "                                                                                                  \n",
      " block2_sepconv1 (SeparableConv  (None, 13, 13, 128)  8768       ['block1_conv2_act[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block2_sepconv1_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2_sepconv2_act (Activatio  (None, 13, 13, 128)  0          ['block2_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block2_sepconv2 (SeparableConv  (None, 13, 13, 128)  17536      ['block2_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block2_sepconv2_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 7, 7, 128)    8192        ['block1_conv2_act[0][0]']       \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 7, 7, 128)    0           ['block2_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 7, 7, 128)   512         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 7, 7, 128)    0           ['block2_pool[0][0]',            \n",
      "                                                                  'batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " block3_sepconv1_act (Activatio  (None, 7, 7, 128)   0           ['add[0][0]']                    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block3_sepconv1 (SeparableConv  (None, 7, 7, 256)   33920       ['block3_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3_sepconv1_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3_sepconv2_act (Activatio  (None, 7, 7, 256)   0           ['block3_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block3_sepconv2 (SeparableConv  (None, 7, 7, 256)   67840       ['block3_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3_sepconv2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 4, 4, 256)    32768       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 4, 4, 256)    0           ['block3_pool[0][0]',            \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " block4_sepconv1_act (Activatio  (None, 4, 4, 256)   0           ['add_1[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block4_sepconv1 (SeparableConv  (None, 4, 4, 728)   188672      ['block4_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4_sepconv1_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4_sepconv2_act (Activatio  (None, 4, 4, 728)   0           ['block4_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block4_sepconv2 (SeparableConv  (None, 4, 4, 728)   536536      ['block4_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4_sepconv2_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 2, 2, 728)    186368      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 2, 2, 728)    0           ['block4_sepconv2_bn[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 2, 2, 728)   2912        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 2, 728)    0           ['block4_pool[0][0]',            \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " block5_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_2[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block5_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 2, 2, 728)    0           ['block5_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " block6_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_3[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block6_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 2, 2, 728)    0           ['block6_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " block7_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_4[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block7_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block7_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 2, 2, 728)    0           ['block7_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " block8_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_5[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block8_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block8_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block8_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block8_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 2, 2, 728)    0           ['block8_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " block9_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_6[0][0]']                  \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv1_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block9_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv1_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv2_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block9_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv2_bn[0][0]']     \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block9_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv3_act[0][0]']    \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block9_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 2, 2, 728)    0           ['block9_sepconv3_bn[0][0]',     \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " block10_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_7[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block10_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block10_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block10_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block10_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 2, 2, 728)    0           ['block10_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " block11_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_8[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block11_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block11_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block11_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block11_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 2, 2, 728)    0           ['block11_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " block12_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_9[0][0]']                  \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block12_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block12_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block12_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv3_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block12_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv3[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 2, 2, 728)    0           ['block12_sepconv3_bn[0][0]',    \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " block13_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_10[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block13_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block13_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block13_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block13_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block13_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block13_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block13_sepconv2 (SeparableCon  (None, 2, 2, 1024)  752024      ['block13_sepconv2_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block13_sepconv2_bn (BatchNorm  (None, 2, 2, 1024)  4096        ['block13_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 1, 1, 1024)   745472      ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " block13_pool (MaxPooling2D)    (None, 1, 1, 1024)   0           ['block13_sepconv2_bn[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 1, 1, 1024)  4096        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 1, 1, 1024)   0           ['block13_pool[0][0]',           \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " block14_sepconv1 (SeparableCon  (None, 1, 1, 1536)  1582080     ['add_11[0][0]']                 \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block14_sepconv1_bn (BatchNorm  (None, 1, 1, 1536)  6144        ['block14_sepconv1[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block14_sepconv1_act (Activati  (None, 1, 1, 1536)  0           ['block14_sepconv1_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " block14_sepconv2 (SeparableCon  (None, 1, 1, 2048)  3159552     ['block14_sepconv1_act[0][0]']   \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " block14_sepconv2_bn (BatchNorm  (None, 1, 1, 2048)  8192        ['block14_sepconv2[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block14_sepconv2_act (Activati  (None, 1, 1, 2048)  0           ['block14_sepconv2_bn[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " fc1 (Dense)                    (None, 50)           102450      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 10)           510         ['fc1[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,964,440\n",
      "Trainable params: 20,909,912\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665/665 [==============================] - 78s 103ms/step - loss: 0.7672 - accuracy: 0.7475 - val_loss: 0.6129 - val_accuracy: 0.8172 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "665/665 [==============================] - 65s 98ms/step - loss: 0.4076 - accuracy: 0.8683 - val_loss: 0.3907 - val_accuracy: 0.8725 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "665/665 [==============================] - 67s 100ms/step - loss: 0.3131 - accuracy: 0.8981 - val_loss: 0.5870 - val_accuracy: 0.8048 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "665/665 [==============================] - 69s 103ms/step - loss: 0.2551 - accuracy: 0.9169 - val_loss: 0.4925 - val_accuracy: 0.8572 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "665/665 [==============================] - 68s 103ms/step - loss: 0.2122 - accuracy: 0.9321 - val_loss: 0.4695 - val_accuracy: 0.8653 - lr: 0.0010\n",
      "Epoch 6/40\n",
      "665/665 [==============================] - 67s 101ms/step - loss: 0.1792 - accuracy: 0.9411 - val_loss: 0.3210 - val_accuracy: 0.9007 - lr: 0.0010\n",
      "Epoch 7/40\n",
      "665/665 [==============================] - 68s 102ms/step - loss: 0.1515 - accuracy: 0.9503 - val_loss: 0.4181 - val_accuracy: 0.8816 - lr: 0.0010\n",
      "Epoch 8/40\n",
      "665/665 [==============================] - 67s 101ms/step - loss: 0.1318 - accuracy: 0.9561 - val_loss: 0.6191 - val_accuracy: 0.8451 - lr: 0.0010\n",
      "Epoch 9/40\n",
      "665/665 [==============================] - 69s 103ms/step - loss: 0.1552 - accuracy: 0.9510 - val_loss: 0.3867 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 10/40\n",
      "665/665 [==============================] - 68s 102ms/step - loss: 0.1161 - accuracy: 0.9622 - val_loss: 0.4518 - val_accuracy: 0.8736 - lr: 0.0010\n",
      "Epoch 11/40\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9620\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "665/665 [==============================] - 69s 103ms/step - loss: 0.1168 - accuracy: 0.9620 - val_loss: 0.3243 - val_accuracy: 0.9081 - lr: 0.0010\n",
      "Epoch 12/40\n",
      "665/665 [==============================] - 69s 104ms/step - loss: 0.0392 - accuracy: 0.9871 - val_loss: 0.2429 - val_accuracy: 0.9355 - lr: 2.0000e-04\n",
      "Epoch 13/40\n",
      "665/665 [==============================] - 67s 101ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.2650 - val_accuracy: 0.9331 - lr: 2.0000e-04\n",
      "Epoch 14/40\n",
      "665/665 [==============================] - 67s 100ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.2775 - val_accuracy: 0.9372 - lr: 2.0000e-04\n",
      "Epoch 15/40\n",
      "665/665 [==============================] - 67s 100ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.3014 - val_accuracy: 0.9361 - lr: 2.0000e-04\n",
      "Epoch 16/40\n",
      "665/665 [==============================] - 67s 101ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.4755 - val_accuracy: 0.9051 - lr: 2.0000e-04\n",
      "Epoch 17/40\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9960\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "665/665 [==============================] - 71s 107ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.2987 - val_accuracy: 0.9385 - lr: 2.0000e-04\n",
      "Epoch 18/40\n",
      "665/665 [==============================] - 71s 106ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.2992 - val_accuracy: 0.9381 - lr: 4.0000e-05\n",
      "Epoch 19/40\n",
      "665/665 [==============================] - 71s 106ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.3020 - val_accuracy: 0.9380 - lr: 4.0000e-05\n",
      "Epoch 20/40\n",
      "665/665 [==============================] - 70s 106ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.3095 - val_accuracy: 0.9401 - lr: 4.0000e-05\n",
      "Epoch 21/40\n",
      "665/665 [==============================] - 71s 107ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.3135 - val_accuracy: 0.9391 - lr: 4.0000e-05\n",
      "Epoch 22/40\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "665/665 [==============================] - 72s 108ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.3206 - val_accuracy: 0.9393 - lr: 4.0000e-05\n",
      "Epoch 00022: early stopping\n",
      "157/157 [==============================] - 5s 31ms/step - loss: 0.3858 - accuracy: 0.9295\n",
      "테스트 데이터 세트 evaluation 결과: [0.38580048084259033, 0.9294999837875366]\n"
     ]
    }
   ],
   "source": [
    "# 만약 image_size를 64로 하려면 반드시 RAM이 여유분이 충분히 있는지 확인\n",
    "history, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1652092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터세트 검증 결과: [0.38580048084259033, 0.9294999837875366]\n"
     ]
    }
   ],
   "source": [
    "print('테스트 데이터세트 검증 결과:', evaluation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754affe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_history(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.xticks(np.arange(0, 30, 2))\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='valid')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
