{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-13T18:05:56.283628Z",
     "iopub.status.busy": "2022-04-13T18:05:56.283365Z",
     "iopub.status.idle": "2022-04-13T18:05:56.289801Z",
     "shell.execute_reply": "2022-04-13T18:05:56.288961Z",
     "shell.execute_reply.started": "2022-04-13T18:05:56.283592Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 수행.\n",
    "* 학습/검증/테스트 데이터 세트로 나누고 원-핫 인코딩 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:06:09.325383Z",
     "iopub.status.busy": "2022-04-13T18:06:09.325117Z",
     "iopub.status.idle": "2022-04-13T18:06:20.248318Z",
     "shell.execute_reply": "2022-04-13T18:06:20.247576Z",
     "shell.execute_reply.started": "2022-04-13T18:06:09.325338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 12s 0us/step\n",
      "170508288/170498071 [==============================] - 12s 0us/step\n",
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random as python_random\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n",
    "def set_random_seed(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    python_random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
    "def get_preprocessed_data(images, labels):\n",
    "    \n",
    "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
    "    images = np.array(images/255.0, dtype=np.float32)\n",
    "    labels = np.array(labels, dtype=np.float32)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
    "def get_preprocessed_ohe(images, labels):\n",
    "    images, labels = get_preprocessed_data(images, labels)\n",
    "    # OHE 적용 \n",
    "    oh_labels = to_categorical(labels)\n",
    "    return images, oh_labels\n",
    "\n",
    "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
    "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
    "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
    "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
    "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
    "    \n",
    "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
    "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
    "    \n",
    "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n",
    "\n",
    "\n",
    "# random seed는 2021로 고정.\n",
    "set_random_seed(2021)\n",
    "# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
    "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
    "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
    "\n",
    "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:06:24.130735Z",
     "iopub.status.busy": "2022-04-13T18:06:24.130482Z",
     "iopub.status.idle": "2022-04-13T18:06:24.135361Z",
     "shell.execute_reply": "2022-04-13T18:06:24.133803Z",
     "shell.execute_reply.started": "2022-04-13T18:06:24.130707Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:06:44.661577Z",
     "iopub.status.busy": "2022-04-13T18:06:44.661140Z",
     "iopub.status.idle": "2022-04-13T18:06:44.694526Z",
     "shell.execute_reply": "2022-04-13T18:06:44.693453Z",
     "shell.execute_reply.started": "2022-04-13T18:06:44.661532Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "\n",
    "def create_model(verbose=False):\n",
    "    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "    #x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=3, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    # cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(300, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(rate=0.3)(x)\n",
    "    output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    if verbose:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 300)               614700    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                3010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906,254\n",
      "Trainable params: 905,486\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x251714050a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate와 Early Stopping을 위한 Callback 생성 \n",
    "* Learning rate 동적 변경은 ReduceLROnPlateau,  모델 Ealry Stopping은 EarlyStopping Callback을 이용.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:14:37.059394Z",
     "iopub.status.busy": "2022-04-13T18:14:37.059096Z",
     "iopub.status.idle": "2022-04-13T18:14:37.830391Z",
     "shell.execute_reply": "2022-04-13T18:14:37.829500Z",
     "shell.execute_reply.started": "2022-04-13T18:14:37.059364Z"
    }
   },
   "outputs": [],
   "source": [
    "# ModelCheckpoint를 동작시키기 전에 기존 저장된 모델은 모두 삭제 \n",
    "!rm *.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:14:43.973731Z",
     "iopub.status.busy": "2022-04-13T18:14:43.973453Z",
     "iopub.status.idle": "2022-04-13T18:18:55.191738Z",
     "shell.execute_reply": "2022-04-13T18:18:55.190952Z",
     "shell.execute_reply.started": "2022-04-13T18:14:43.973701Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# validation loss가 향상되는 모델만 저장.\n",
    "mcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n",
    "                         save_best_only=True, save_weights_only=True, mode='min', period=1, verbose=0)\n",
    "\n",
    "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=32, epochs=30, shuffle=True,\n",
    "                    validation_data=(val_images, val_oh_labels),  \n",
    "                    callbacks=[mcp_cb, rlr_cb, ely_cb] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:20:19.582954Z",
     "iopub.status.busy": "2022-04-13T18:20:19.582650Z",
     "iopub.status.idle": "2022-04-13T18:21:09.316023Z",
     "shell.execute_reply": "2022-04-13T18:21:09.315310Z",
     "shell.execute_reply.started": "2022-04-13T18:20:19.582921Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:23:15.787875Z",
     "iopub.status.busy": "2022-04-13T18:23:15.787283Z",
     "iopub.status.idle": "2022-04-13T18:23:16.493628Z",
     "shell.execute_reply": "2022-04-13T18:23:16.492891Z",
     "shell.execute_reply.started": "2022-04-13T18:23:15.787837Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -lia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적 weight를 모델로 재 로딩한 다음에 테스트 데이터로 다시 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:24:51.363721Z",
     "iopub.status.busy": "2022-04-13T18:24:51.363037Z",
     "iopub.status.idle": "2022-04-13T18:24:51.521082Z",
     "shell.execute_reply": "2022-04-13T18:24:51.520348Z",
     "shell.execute_reply.started": "2022-04-13T18:24:51.363685Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights('/kaggle/working/weights.20-0.54.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:25:06.459623Z",
     "iopub.status.busy": "2022-04-13T18:25:06.458827Z",
     "iopub.status.idle": "2022-04-13T18:25:08.396177Z",
     "shell.execute_reply": "2022-04-13T18:25:08.395291Z",
     "shell.execute_reply.started": "2022-04-13T18:25:06.459584Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:47:23.370256Z",
     "iopub.status.busy": "2022-04-13T18:47:23.369671Z",
     "iopub.status.idle": "2022-04-13T18:47:23.642561Z",
     "shell.execute_reply": "2022-04-13T18:47:23.641875Z",
     "shell.execute_reply.started": "2022-04-13T18:47:23.370221Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_history(history):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.yticks(np.arange(0, 1, 0.05))\n",
    "    plt.xticks(np.arange(0, 30, 2))\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='valid')\n",
    "    plt.legend()\n",
    "    \n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필터의 개수를 증가시켜 테스트\n",
    "* Conv Layer의 필터를 기존보다 2배씩 증가\n",
    "* 맨 마지막 Conv는 512로 대폭 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:33:02.872484Z",
     "iopub.status.busy": "2022-04-13T18:33:02.872206Z",
     "iopub.status.idle": "2022-04-13T18:33:03.038374Z",
     "shell.execute_reply": "2022-04-13T18:33:03.037674Z",
     "shell.execute_reply.started": "2022-04-13T18:33:02.872456Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "#x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# 512 filters Conv layer 추가\n",
    "x = Conv2D(filters=512, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', name='fc1')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:40:52.258467Z",
     "iopub.status.busy": "2022-04-13T18:40:52.257942Z",
     "iopub.status.idle": "2022-04-13T18:46:44.122136Z",
     "shell.execute_reply": "2022-04-13T18:46:44.121399Z",
     "shell.execute_reply.started": "2022-04-13T18:40:52.258431Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=32, epochs=30, shuffle=True,\n",
    "                    validation_data=(val_images, val_oh_labels),  \n",
    "                    callbacks=[rlr_cb, ely_cb] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:47:33.866773Z",
     "iopub.status.busy": "2022-04-13T18:47:33.866158Z",
     "iopub.status.idle": "2022-04-13T18:47:36.982391Z",
     "shell.execute_reply": "2022-04-13T18:47:36.981576Z",
     "shell.execute_reply.started": "2022-04-13T18:47:33.866740Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_labels)\n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 맨 마지막 Conv + MaxPooling 대신 맨 마지막 Conv의 Strides를 2로 하여 Feature map 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:47:50.305729Z",
     "iopub.status.busy": "2022-04-13T18:47:50.305455Z",
     "iopub.status.idle": "2022-04-13T18:47:50.464618Z",
     "shell.execute_reply": "2022-04-13T18:47:50.463934Z",
     "shell.execute_reply.started": "2022-04-13T18:47:50.305699Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# 512 filters Conv layer 추가하되 이후 MaxPooling을 적용하지 않고 strides는 2로 변경하여 출력 feature map 크기 조정\n",
    "x = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', name='fc1')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T18:47:58.798362Z",
     "iopub.status.busy": "2022-04-13T18:47:58.798113Z",
     "iopub.status.idle": "2022-04-13T18:52:21.147390Z",
     "shell.execute_reply": "2022-04-13T18:52:21.146280Z",
     "shell.execute_reply.started": "2022-04-13T18:47:58.798334Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=32, epochs=30, shuffle=True,\n",
    "                    validation_data=(val_images, val_oh_labels),  \n",
    "                    callbacks=[rlr_cb, ely_cb] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T19:03:00.680666Z",
     "iopub.status.busy": "2022-04-13T19:03:00.680409Z",
     "iopub.status.idle": "2022-04-13T19:03:02.737373Z",
     "shell.execute_reply": "2022-04-13T19:03:02.736579Z",
     "shell.execute_reply.started": "2022-04-13T19:03:00.680638Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_labels)\n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Average Pooling의 적용\n",
    "* Global Average Pooling은 피처맵의 가로x세로의 특정 영역을 Sub sampling 않고, 채널별로 평균 값을 추출\n",
    "* 충분히 Feature map의 채널수가 많을 경우 이를 적용. 채널수가 적다면 Flatten이 유리. \n",
    "* Flatten-> Classification Dense Layer로 이어지면서 많은 파라미터들로 인한 오버피팅 유발 가능성 증대 및 학습 시간 늘어남. \n",
    "* 맨 마지막 Feature Map의 채널 수가 충분히 크다면 GlobalAveragePooling2D를 적용하여 Flatten을 제거하는데 더 유리 할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T19:13:45.121401Z",
     "iopub.status.busy": "2022-04-13T19:13:45.120846Z",
     "iopub.status.idle": "2022-04-13T19:13:45.284762Z",
     "shell.execute_reply": "2022-04-13T19:13:45.283949Z",
     "shell.execute_reply.started": "2022-04-13T19:13:45.121366Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "#x = Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu')(input_tensor)\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# Flatten 대신 Global AveragePooling 을 적용. \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(50, activation='relu', name='fc1')(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T19:13:48.293484Z",
     "iopub.status.busy": "2022-04-13T19:13:48.293019Z",
     "iopub.status.idle": "2022-04-13T19:17:55.573255Z",
     "shell.execute_reply": "2022-04-13T19:17:55.572548Z",
     "shell.execute_reply.started": "2022-04-13T19:13:48.293449Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=32, epochs=30, shuffle=True,\n",
    "                    validation_data=(val_images, val_oh_labels),  \n",
    "                    callbacks=[rlr_cb, ely_cb] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T19:26:29.553760Z",
     "iopub.status.busy": "2022-04-13T19:26:29.553506Z",
     "iopub.status.idle": "2022-04-13T19:27:14.186140Z",
     "shell.execute_reply": "2022-04-13T19:27:14.185297Z",
     "shell.execute_reply.started": "2022-04-13T19:26:29.553732Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_labels)\n",
    "show_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치 규제(Weight Regularizations)\n",
    "* 개별 layer별로 tensorflow.keras.regularizers의 l1, l2, l1_l2 를 이용하여 가중치 규제를 적용할 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T19:27:17.817525Z",
     "iopub.status.busy": "2022-04-13T19:27:17.816981Z",
     "iopub.status.idle": "2022-04-13T19:27:17.990053Z",
     "shell.execute_reply": "2022-04-13T19:27:17.989350Z",
     "shell.execute_reply.started": "2022-04-13T19:27:17.817487Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), padding='same', kernel_regularizer=l2(0.00001))(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), padding='same', kernel_regularizer=l2(0.00001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(filters=256, kernel_size=3, padding='same', kernel_regularizer=l2(1e-5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# 512 filters Conv layer 추가하되 이후 MaxPooling을 적용하지 않고 strides는 2로 변경하여 출력 feature map 크기 조정\n",
    "x = Conv2D(filters=512, kernel_size=3, strides=2, padding='same', kernel_regularizer=l2(1e-5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "# cifar10의 클래스가 10개 이므로 마지막 classification의 Dense layer units갯수는 10\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(300, activation='relu', kernel_regularizer=l2(1e-5), name='fc1')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "output = Dense(10, activation='softmax', name='output')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T19:27:20.012456Z",
     "iopub.status.busy": "2022-04-13T19:27:20.011758Z",
     "iopub.status.idle": "2022-04-13T19:31:46.134681Z",
     "shell.execute_reply": "2022-04-13T19:31:46.133948Z",
     "shell.execute_reply.started": "2022-04-13T19:27:20.012422Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
    "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
    "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
    "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=32, epochs=30, shuffle=True,\n",
    "                    validation_data=(val_images, val_oh_labels),  \n",
    "                    callbacks=[rlr_cb, ely_cb] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_oh_labels)\n",
    "show_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
